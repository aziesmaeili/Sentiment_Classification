{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ae07525\\python\\python37-32\\lib\\site-packages\\gensim\\utils.py:1212: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ae07525\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import os\n",
    "import nltk\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "import string\n",
    "from nltk.stem import SnowballStemmer\n",
    "from string import punctuation\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import gensim \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from collections import Counter\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import logging\n",
    "from numpy import loadtxt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from time import strptime\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from bokeh.models import ColumnDataSource, LabelSet\n",
    "from bokeh.io import push_notebook, output_notebook\n",
    "nltk.download('stopwords')\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "%matplotlib inline\n",
    "import gzip\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import pickle\n",
    "from bokeh.plotting import figure, show\n",
    "from bokeh.io import push_notebook, output_notebook\n",
    "from bokeh.models import ColumnDataSource, LabelSet\n",
    "from sklearn.manifold import TSNE\n",
    "from bokeh.plotting import figure, show\n",
    "from bokeh.io import push_notebook, output_notebook\n",
    "from bokeh.models import ColumnDataSource, LabelSet\n",
    "import unicodedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \n",
    "    ## Remove puncuation\n",
    "    text = text.translate(string.punctuation)\n",
    "    \n",
    "    ## Convert words to lower case and split them\n",
    "    text = text.lower().split()\n",
    "    \n",
    "    ## Remove stop words\n",
    "    stops = set(stopwords.words(\"english\"))\n",
    "    #text = [w for w in text if not w in stops and len(w) > 2]    \n",
    "    text = \" \".join(text)\n",
    "    ## Clean the text\n",
    "    text = re.sub(r\"[^A-Za-z0-9^,!.\\/'+-=]\", \" \", text)\n",
    "    text = re.sub(r\"what's\", \"what is \", text)\n",
    "    text = re.sub(r\"\\'s\", \" \", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    text = re.sub(r\"i'm\", \"i am \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    text = re.sub(r\",\", \" \", text)\n",
    "    text = re.sub(r\"\\.\", \" \", text)\n",
    "    text = re.sub(r\"!\", \" ! \", text)\n",
    "    text = re.sub(r\"\\/\", \" \", text)\n",
    "    text = re.sub(r\"\\^\", \" ^ \", text)\n",
    "    text = re.sub(r\"\\+\", \" + \", text)\n",
    "    text = re.sub(r\"\\-\", \" - \", text)\n",
    "    text = re.sub(r\"\\=\", \" = \", text)\n",
    "    text = re.sub(r\"'\", \" \", text)\n",
    "    text = re.sub(r\"(\\d+)(k)\", r\"\\g<1>000\", text)\n",
    "    text = re.sub(r\":\", \" : \", text)\n",
    "    text = re.sub(r\" e g \", \" eg \", text)\n",
    "    text = re.sub(r\" b g \", \" bg \", text)\n",
    "    text = re.sub(r\"\\0s\", \"0\", text)\n",
    "    text = re.sub(r\"e - mail\", \"email\", text)\n",
    "    text = re.sub(r\"j k\", \"jk\", text)\n",
    "    text = re.sub(r\"\\s{2,}\", \" \", text)\n",
    "    text = re.sub(r\"other\", \"\", text)\n",
    "    text = re.sub(r\"-\", \"\", text)\n",
    "    text = re.sub(r\":\", \"\", text)\n",
    "    text = re.sub(r\"an\", \"\", text)\n",
    "\n",
    "    ## Stemming\n",
    "    text = text.split()\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lem_words = [lemmatizer.lemmatize(word) for word in text]\n",
    "    text = \" \".join(lem_words)\n",
    "\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing and cleaning text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocessing(df):\n",
    "\n",
    "\n",
    "    df['Date']=pd.to_datetime(df['Submission Date'])\n",
    "    df['Month'] = df['Date'].dt.month\n",
    "    df['Year'] = df['Date'].dt.year\n",
    "\n",
    "    df['Month']=df['Month'].astype(str)\n",
    "    print ('\\n')\n",
    "    \n",
    "    #print (\"Number of overall words in body\",df['Comments'].apply(lambda x: len(x.split(' '))).sum())\n",
    "    print ('\\n')\n",
    "\n",
    "\n",
    "    look_up = {'1': 'Jan', '2': 'Feb', '3': 'Mar', '4':\n",
    "           'Apr', '5': 'May', '6': 'Jun', '7': 'Jul', '8': 'Aug', '9': 'Sep', '10': 'Oct', '11': 'Nov', '12': 'Dec'}\n",
    "\n",
    "    df['Month'] = df['Month'].apply(lambda x: look_up[x])\n",
    "    conditions = [(df['Overall Rating'] >3)  ,(df['Overall Rating'] ==3) ,(df['Overall Rating']< 3)]\n",
    "    choices = ['positive', 'neutral', 'negative']\n",
    "  \n",
    "    \n",
    "    df['feeling'] = np.select(conditions, choices, default='black')\n",
    "    df[\"label\"]=df[\"feeling\"].astype('category').cat.codes\n",
    "    df.Comments = df.Comments.str.replace('\\d+', '')\n",
    "    df['Comments'] = df['Comments'].astype(str)\n",
    "\n",
    "    print (\"Distribution of actual \",df.groupby('feeling').size())\n",
    "    df['Comments'] = df['Comments'].str.lower()\n",
    "    df['Comments'] = df['Comments'].str.strip()\n",
    "    df = df[df['Comments'] != '??']\n",
    "    df = df[df['Comments'] != '']\n",
    "        \n",
    "    df['comment'] = df['Comments'].apply(clean_text)\n",
    "    #print (\"Number of overall words after cleaning\",df['comment'].apply(lambda x: len(x.split(' '))).sum())\n",
    "\n",
    "    print(df['comment'][0:2])\n",
    "    \n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set HyperParameter for Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train three classification algorithms random forest,  naive bayes and logistic regression and save in Pickel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_model(random_grid , training_data):\n",
    "\n",
    "    rf= RandomForestClassifier()\n",
    "    rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 3, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "    rfc_hyper_search = Pipeline([('vect', CountVectorizer()),('tfidf', TfidfTransformer()),\n",
    "                ('clf', rf_random),])\n",
    "    rfc_hyper_search.fit( training_data.comment,  training_data.feeling)\n",
    "    \n",
    "    print (\"Save RF Model in pickel\")\n",
    "    pkl_filename = \"pickle_model_RF.pkl\"  \n",
    "    with open(pkl_filename, 'wb') as file:  \n",
    "        pickle.dump(rfc_hyper_search, file)   \n",
    "    my_tags = ['negative','neutral','positive']\n",
    "    y_pred_HP_RF= rfc_hyper_search.predict( training_data.comment)\n",
    "    print('accuracy in Random Forest %s' % accuracy_score(  training_data.feeling, y_pred_HP_RF))\n",
    "    print ('Confution Matrix in Random Forest')\n",
    "    print(classification_report( training_data.feeling, y_pred_HP_RF,target_names=my_tags))\n",
    "    print (confusion_matrix(training_data.feeling, y_pred_HP_RF, my_tags))\n",
    "    training_data[\"Sentimin_feeling_RF\"]=y_pred_HP_RF\n",
    "\n",
    "    my_tags = ['negative','neutral','positive']\n",
    "    nb = Pipeline([('vect', CountVectorizer()),\n",
    "               ('tfidf', TfidfTransformer()),\n",
    "               ('clf', MultinomialNB()),\n",
    "              ])\n",
    "    nb.fit(training_data.comment,  training_data.feeling)    \n",
    "    print (\"Save Naive Base in pickel\")\n",
    "    pkl_filename_nb = \"pickle_model_NB.pkl\"  \n",
    "    with open(pkl_filename_nb, 'wb') as file:  \n",
    "        pickle.dump(nb, file)\n",
    "    y_pred_nb= nb.predict( training_data.comment)\n",
    "    print('accuracy Naive Base%s' % accuracy_score(  training_data.feeling, y_pred_nb))\n",
    "    print ('Confution Matrix Naive Base')\n",
    "    print(classification_report( training_data.feeling,  y_pred_nb,target_names=my_tags))\n",
    "    print (confusion_matrix(training_data.feeling,  y_pred_nb, my_tags))\n",
    "    training_data[\"Sentimin_feeling_NB\"]=y_pred_nb\n",
    "   \n",
    "           \n",
    "    logreg = Pipeline([('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', LogisticRegression(n_jobs=1, C=1e5)),\n",
    "               ])\n",
    "    logreg.fit(training_data.comment,  training_data.feeling)\n",
    "    \n",
    "    print (\"Save Logistic Regression in pickel\")\n",
    "    pkl_filename_lg = \"pickle_model_LG.pkl\"  \n",
    "    with open(pkl_filename_lg, 'wb') as file:  \n",
    "        pickle.dump(logreg, file)  \n",
    "                 \n",
    "    y_pred_lg= logreg.predict( training_data.comment)\n",
    "    print('accuracy Logestic Regression %s' % accuracy_score(  training_data.feeling, y_pred_lg))\n",
    "    print ('Confution Matrix Logistic Regression')\n",
    "    print(classification_report( training_data.feeling,  y_pred_lg,target_names=my_tags))\n",
    "    print (confusion_matrix(training_data.feeling,  y_pred_lg, my_tags))\n",
    "    training_data[\"Sentimin_feeling_LG\"]=y_pred_lg\n",
    "    print ( training_data[0:3])\n",
    "    \n",
    "    return training_data, rfc_hyper_search, nb, logreg\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load models from pickel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Random Forest Model\n",
      "Load Naive Base Model \n",
      "Load Logistic Regression\n"
     ]
    }
   ],
   "source": [
    "print (\"Load Random Forest Model\")    \n",
    "pickle_in_RF = open(\"pickle_model_RF.pkl\",\"rb\")\n",
    "load_model_sentiment_RF = pickle.load(pickle_in_RF)\n",
    "\n",
    "print (\"Load Naive Base Model \")    \n",
    "pickle_in_NB = open(\"pickle_model_NB.pkl\",\"rb\")\n",
    "load_model_sentiment_NB = pickle.load(pickle_in_NB) \n",
    "\n",
    "\n",
    "print (\"Load Logistic Regression\")    \n",
    "pickle_in_LG = open(\"pickle_model_LG.pkl\",\"rb\")\n",
    "load_model_sentiment_LG = pickle.load(pickle_in_LG) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Precicting new comment feeling by sentiment classification\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model was trained by Opinoin lab from Jan 2017 to Oct 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_evaluation(new_review,load_model_sentiment_RF,load_model_sentiment_NB,load_model_sentiment_LG):\n",
    "    \n",
    "    my_tags = ['negative','neutral','positive']\n",
    "    sentiment_random_forest= load_model_sentiment_RF.predict(new_review.comment)\n",
    "    print('accuracy test Random Forest %s' % accuracy_score( new_review.feeling, sentiment_random_forest))\n",
    "    print ('Confution Matrix test Random Forest')\n",
    "    print(classification_report(new_review.feeling, sentiment_random_forest,target_names=my_tags))\n",
    "    new_review[\"sentiment_random_forest\"]=sentiment_random_forest\n",
    "    print (\"Distribution of \",new_review.groupby('sentiment_random_forest').size())\n",
    "    print (new_review[0:3])\n",
    "    print (\"Load Naive Base Model \")    \n",
    "    new_sentiment_NB= load_model_sentiment_NB.predict(new_review.comment)\n",
    "\n",
    "    print('accuracy test Naive Base %s' % accuracy_score( new_review.feeling, new_sentiment_NB))\n",
    "    print ('Confution Matrix test Random Forest')\n",
    "    print(classification_report(new_review.feeling, new_sentiment_NB,target_names=my_tags))\n",
    "\n",
    "    new_review[\"Sentimin_NiveBase\"]=new_sentiment_NB\n",
    "    print (\"Distribution of \",new_review.groupby('Sentimin_NiveBase').size())\n",
    "\n",
    "    new_sentiment_LG= load_model_sentiment_LG.predict(new_review.comment)\n",
    "\n",
    "    print('accuracy test LogisticRegression %s' % accuracy_score( new_review.feeling, new_sentiment_LG))\n",
    "    print ('Confution Matrix test Random Forest')\n",
    "    print(classification_report(new_review.feeling, new_sentiment_LG,target_names=my_tags))\n",
    "\n",
    "    new_review[\"Sentimin_Logistic_Regression\"]=new_sentiment_LG\n",
    "    print (\"Distribution of \",new_review.groupby('Sentimin_Logistic_Regression').size())\n",
    "\n",
    "    new_review['majority']= np.where((new_review['sentiment_random_forest'].str.contains('negative'))&( new_review['Sentimin_Logistic_Regression'].str.contains ('positive|neutral'))&( new_review['Sentimin_NiveBase'].str.contains('positive|neutral')),'neutral', new_review.sentiment_random_forest)\n",
    "    new_review['majority']= np.where((new_review['sentiment_random_forest'] == 'positive')&(new_review['Sentimin_Logistic_Regression'] == 'negative')&(new_review['Sentimin_NiveBase'] == 'negative'),'neutral',new_review['majority'])\n",
    "    \n",
    "    print (new_review[0:3])  \n",
    "    print (\"Saving new_senmtimet_label in CSV format\")\n",
    "    new_review.to_csv('C://Users//ae07525//Desktop//New_folder//New_text_Sentiment_majority.csv')\n",
    "    \n",
    "    return new_review\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload  dataset opinion lab from Jan 2017 to Feb 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "opinionlab2017182019=pd.read_csv(\"C://Users//ae07525//PycharmProjects//bachtime//formatted_Feb25.csv\", error_bad_lines=False,encoding='utf-8')\n",
    "\n",
    "opinionlab2017=pd.read_csv(\"OpinionLab_012017_122017.csv\", error_bad_lines=False, encoding=\"ISO-8859-1\")\n",
    "opinionlab=pd.concat([opinionlab2017,opinionlab2017182019])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove some noisy comments that is similar to Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(149900, 9)\n",
      "(89045, 9)\n"
     ]
    }
   ],
   "source": [
    "print (opinionlab.shape)\n",
    "opinionlab.dropna()\n",
    "# drop duplicates\n",
    "opinionlab.drop_duplicates(subset=None, keep='first', inplace=True)\n",
    "#drop non ascii chars\n",
    "\n",
    "opinionlab = opinionlab[opinionlab.Comments.str.count(' ')>1]\n",
    "\n",
    "opinionlab=opinionlab.dropna()\n",
    "opinionlab=opinionlab[~opinionlab.Comments.str.contains(\"Farhat Deeba\")]\n",
    "opinionlab=opinionlab[~opinionlab.Comments.str.contains(\"farhat deeba\")]\n",
    "opinionlab=opinionlab[~opinionlab.Comments.str.contains(\"ï¼ xì ¼ê²½ì xë ï¼\")]\n",
    "opinionlab=opinionlab[~opinionlab.Comments.str.contains(\"ï¼\")]\n",
    "opinionlab=opinionlab[~opinionlab.Comments.str.contains(\"Farhat Deeba\")]\n",
    "opinionlab=opinionlab[~opinionlab.Comments.str.contains(\"Ã¯Â¼Â‚xÃ¬Â‹ÂœÃªÂ°Â\")]\n",
    "opinionlab=opinionlab[~opinionlab.Comments.str.contains(\"¼ê²½ìƒ‰Â·ë\")]\n",
    "opinionlab=opinionlab[~opinionlab.Comments.str.contains(\"xxzxzdrddxxxxxxxf\")]\n",
    "opinionlab=opinionlab[~opinionlab.Comments.str.contains(\"¼ê²½ì\")] \n",
    "opinionlab=opinionlab[~opinionlab.Comments.str.contains(\"Facebook | Facebook\")] \n",
    "opinionlab=opinionlab[~opinionlab.Comments.str.contains(\"farhat deeba xx bird eye circle stony brook ny xxxxx usa\")] \n",
    "\n",
    "\n",
    "print (opinionlab.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "Distribution of actual  feeling\n",
      "negative    53166\n",
      "neutral     15966\n",
      "positive    19913\n",
      "dtype: int64\n",
      "42256           safari comment card test\n",
      "42546    custom variable formatting test\n",
      "Name: comment, dtype: object\n"
     ]
    }
   ],
   "source": [
    "opl=data_preprocessing(opinionlab)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data as training dataset and test dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data for 2017 and 2018 for trining dataset and 2019 for test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15415, 15),\n",
       " (73628, 15),\n",
       " array([2017, 2018], dtype=int64),\n",
       " array([2019], dtype=int64))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "training_data= opl[(opl['Date'] < '2019-01-01')]\n",
    "test_data= opl[(opl['Date'] > '2019-01-01')]\n",
    "\n",
    "test_data.shape, training_data.shape, pd.unique(training_data.Year), pd.unique(test_data.Year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "month and year in training datasetin OPL ['Dec' 'Jan' 'Feb' 'Mar' 'Apr' 'May' 'Jun' 'Jul' 'Aug' 'Sep' 'Oct' 'Nov'] [2017 2018]\n",
      "Month and years in test dataset in OPL ['Jan' 'Feb']\n"
     ]
    }
   ],
   "source": [
    "print (\"Month and years in training datasetin OPL\",pd.unique(training_data.Month),pd.unique(training_data.Year))\n",
    "print (\"Month and year in test dataset in OPL\", pd.unique(test_data.Month))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Call training function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of   9 | elapsed: 18.9min remaining:  5.4min\n",
      "[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed: 26.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save RF Model in pickel\n",
      "accuracy in Random Forest 0.6804962817203751\n",
      "Confution Matrix in Random Forest\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.66      0.99      0.79     45764\n",
      "     neutral       0.89      0.01      0.02     14315\n",
      "    positive       0.85      0.42      0.57     18183\n",
      "\n",
      "   micro avg       0.68      0.68      0.68     78262\n",
      "   macro avg       0.80      0.48      0.46     78262\n",
      "weighted avg       0.75      0.68      0.60     78262\n",
      "\n",
      "[[45373     5   386]\n",
      " [13184   170   961]\n",
      " [10453    16  7714]]\n",
      "Save Naive Base in pickel\n",
      "accuracy Naive Base0.6660320462037771\n",
      "Confution Matrix Naive Base\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.65      0.99      0.78     45764\n",
      "     neutral       0.66      0.03      0.06     14315\n",
      "    positive       0.86      0.35      0.50     18183\n",
      "\n",
      "   micro avg       0.67      0.67      0.67     78262\n",
      "   macro avg       0.72      0.46      0.45     78262\n",
      "weighted avg       0.70      0.67      0.58     78262\n",
      "\n",
      "[[45253    84   427]\n",
      " [13287   441   587]\n",
      " [11606   146  6431]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ae07525\\python\\python37-32\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save Logistic Regression in pickel\n",
      "accuracy Logestic Regression 0.78721474023153\n",
      "Confution Matrix Logistic Regression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.92      0.87     45764\n",
      "     neutral       0.65      0.44      0.52     14315\n",
      "    positive       0.77      0.72      0.74     18183\n",
      "\n",
      "   micro avg       0.79      0.79      0.79     78262\n",
      "   macro avg       0.75      0.69      0.71     78262\n",
      "weighted avg       0.78      0.79      0.78     78262\n",
      "\n",
      "[[42310  1726  1728]\n",
      " [ 5882  6253  2180]\n",
      " [ 3533  1604 13046]]\n",
      "            Source      Submission Date                         Comments  \\\n",
      "42256  Opinion Lab  12/18/2017 04:06 PM         safari comment card test   \n",
      "42546  Opinion Lab  12/21/2017 06:20 AM  custom variable formatting test   \n",
      "42548  Opinion Lab  12/21/2017 06:22 AM    right formatting confirmation   \n",
      "\n",
      "      Browser Name OS Name  Overall Rating   Device Type  \\\n",
      "42256       Safari    OS X               5       Desktop   \n",
      "42546       Safari     iOS               5  Mobile Phone   \n",
      "42548       Safari     iOS               5  Mobile Phone   \n",
      "\n",
      "                                  CommentID       CCSID                Date  \\\n",
      "42256  00000006-1560-e8f9-0000-01606baa5060  1.0013e+12 2017-12-18 16:06:00   \n",
      "42546  00000006-1699-97d5-0000-01607904fc10  1.0013e+12 2017-12-21 06:20:00   \n",
      "42548  00000006-1699-afad-0000-01607906a5d8  1.0013e+12 2017-12-21 06:22:00   \n",
      "\n",
      "      Month  Year   feeling  label                          comment  \\\n",
      "42256   Dec  2017  positive      2         safari comment card test   \n",
      "42546   Dec  2017  positive      2  custom variable formatting test   \n",
      "42548   Dec  2017  positive      2    right formatting confirmation   \n",
      "\n",
      "      Sentimin_feeling_RF Sentimin_feeling_NB Sentimin_feeling_LG  \n",
      "42256            negative            negative            positive  \n",
      "42546            negative            negative            positive  \n",
      "42548            negative            negative            positive  \n"
     ]
    }
   ],
   "source": [
    " training_data, rfc_hyper_search, nb, logreg=train_model(random_grid , training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Test the model in comment that is generated in 2019  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy test Random Forest 0.6864742134284788\n",
      "Confution Matrix test Random Forest\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.68      0.99      0.81      9848\n",
      "     neutral       0.32      0.00      0.01      2716\n",
      "    positive       0.74      0.30      0.42      2851\n",
      "\n",
      "   micro avg       0.69      0.69      0.69     15415\n",
      "   macro avg       0.58      0.43      0.41     15415\n",
      "weighted avg       0.63      0.69      0.60     15415\n",
      "\n",
      "Distribution of  sentiment_random_forest\n",
      "negative    14253\n",
      "neutral        25\n",
      "positive     1137\n",
      "dtype: int64\n",
      "            Source      Submission Date  \\\n",
      "32193  Opinion Lab  01/01/2019 12:04 AM   \n",
      "32197  Opinion Lab  01/01/2019 12:51 AM   \n",
      "32198  Opinion Lab  01/01/2019 01:12 AM   \n",
      "\n",
      "                                                Comments  \\\n",
      "32193             needs to show due date on payment page   \n",
      "32197  please add pending $ totals to the app. would ...   \n",
      "32198  the app is nice but doesn't work more often th...   \n",
      "\n",
      "                            Browser Name OS Name  Overall Rating  \\\n",
      "32193  Mobile Safari UI/WKWebView iPhone     iOS               2   \n",
      "32197  Mobile Safari UI/WKWebView iPhone     iOS               3   \n",
      "32198  Mobile Safari UI/WKWebView iPhone     iOS               4   \n",
      "\n",
      "        Device Type    CommentID          CCSID                Date Month  \\\n",
      "32193  Mobile Phone  15463226400  1001158103302 2019-01-01 00:04:00   Jan   \n",
      "32197  Mobile Phone  15463254600  1001160490330 2019-01-01 00:51:00   Jan   \n",
      "32198  Mobile Phone  15463267200  1001166880106 2019-01-01 01:12:00   Jan   \n",
      "\n",
      "       Year   feeling  label  \\\n",
      "32193  2019  negative      0   \n",
      "32197  2019   neutral      1   \n",
      "32198  2019  positive      2   \n",
      "\n",
      "                                                 comment  \\\n",
      "32193              need to show due date on payment page   \n",
      "32197  please add pending total to the app would be v...   \n",
      "32198  the app is nice but doe not work more often th...   \n",
      "\n",
      "      sentiment_random_forest  \n",
      "32193                negative  \n",
      "32197                positive  \n",
      "32198                negative  \n",
      "Load Naive Base Model \n",
      "accuracy test Naive Base 0.6793383068439831\n",
      "Confution Matrix test Random Forest\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.68      0.99      0.80      9848\n",
      "     neutral       0.48      0.01      0.03      2716\n",
      "    positive       0.76      0.24      0.37      2851\n",
      "\n",
      "   micro avg       0.68      0.68      0.68     15415\n",
      "   macro avg       0.64      0.42      0.40     15415\n",
      "weighted avg       0.66      0.68      0.59     15415\n",
      "\n",
      "Distribution of  Sentimin_NiveBase\n",
      "negative    14417\n",
      "neutral        82\n",
      "positive      916\n",
      "dtype: int64\n",
      "accuracy test LogisticRegression 0.6631852092118067\n",
      "Confution Matrix test Random Forest\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.85      0.80      9848\n",
      "     neutral       0.31      0.20      0.24      2716\n",
      "    positive       0.49      0.48      0.49      2851\n",
      "\n",
      "   micro avg       0.66      0.66      0.66     15415\n",
      "   macro avg       0.52      0.51      0.51     15415\n",
      "weighted avg       0.63      0.66      0.64     15415\n",
      "\n",
      "Distribution of  Sentimin_Logistic_Regression\n",
      "negative    10915\n",
      "neutral      1758\n",
      "positive     2742\n",
      "dtype: int64\n",
      "            Source      Submission Date  \\\n",
      "32193  Opinion Lab  01/01/2019 12:04 AM   \n",
      "32197  Opinion Lab  01/01/2019 12:51 AM   \n",
      "32198  Opinion Lab  01/01/2019 01:12 AM   \n",
      "\n",
      "                                                Comments  \\\n",
      "32193             needs to show due date on payment page   \n",
      "32197  please add pending $ totals to the app. would ...   \n",
      "32198  the app is nice but doesn't work more often th...   \n",
      "\n",
      "                            Browser Name OS Name  Overall Rating  \\\n",
      "32193  Mobile Safari UI/WKWebView iPhone     iOS               2   \n",
      "32197  Mobile Safari UI/WKWebView iPhone     iOS               3   \n",
      "32198  Mobile Safari UI/WKWebView iPhone     iOS               4   \n",
      "\n",
      "        Device Type    CommentID          CCSID                Date Month  \\\n",
      "32193  Mobile Phone  15463226400  1001158103302 2019-01-01 00:04:00   Jan   \n",
      "32197  Mobile Phone  15463254600  1001160490330 2019-01-01 00:51:00   Jan   \n",
      "32198  Mobile Phone  15463267200  1001166880106 2019-01-01 01:12:00   Jan   \n",
      "\n",
      "       Year   feeling  label  \\\n",
      "32193  2019  negative      0   \n",
      "32197  2019   neutral      1   \n",
      "32198  2019  positive      2   \n",
      "\n",
      "                                                 comment  \\\n",
      "32193              need to show due date on payment page   \n",
      "32197  please add pending total to the app would be v...   \n",
      "32198  the app is nice but doe not work more often th...   \n",
      "\n",
      "      sentiment_random_forest Sentimin_NiveBase Sentimin_Logistic_Regression  \\\n",
      "32193                negative          negative                      neutral   \n",
      "32197                positive          positive                     positive   \n",
      "32198                negative          negative                     positive   \n",
      "\n",
      "       majority  \n",
      "32193  negative  \n",
      "32197  positive  \n",
      "32198  negative  \n",
      "Saving new_senmtimet_label in CSV format\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_data=prediction_evaluation(test_data,load_model_sentiment_RF,load_model_sentiment_NB,load_model_sentiment_LG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
